{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gym\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import Linear\n",
    "import cartpole_data\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pythonprogramming.net/openai-cartpole-neural-network-example-machine-learning-tutorial/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_steps = 1000\n",
    "score_requirement = 100\n",
    "initial_games = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accepted score: 109.21428571428571\n",
      "Median score for accepted scores: 106.0\n",
      "Counter({102.0: 8, 106.0: 6, 101.0: 6, 103.0: 4, 104.0: 4, 100.0: 3, 119.0: 3, 107.0: 2, 120.0: 2, 105.0: 2, 109.0: 2, 116.0: 2, 115.0: 1, 113.0: 1, 138.0: 1, 127.0: 1, 130.0: 1, 132.0: 1, 118.0: 1, 124.0: 1, 108.0: 1, 122.0: 1, 111.0: 1, 121.0: 1})\n"
     ]
    }
   ],
   "source": [
    "training_data = cartpole_data.initial_population(goal_steps,score_requirement,initial_games)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training testing and validation data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class make_Dataset(Dataset):\n",
    "    def __init__(self, mode):\n",
    "\n",
    "        # read in trainig data\n",
    "\n",
    "        observations = np.array([training_data[i][0] for i in range(len(training_data))])\n",
    "        actions = np.array([training_data[i][1] for i in range(len(training_data))])\n",
    "\n",
    "        observations = torch.tensor(observations , dtype = torch.float)\n",
    "        actions = torch.tensor(actions , dtype = torch.float)\n",
    "        realizations = len(observations)\n",
    "        if   mode=='train':  \n",
    "            size, offset = int(realizations*0.70), int(realizations*0.00)\n",
    "        elif mode=='valid':  \n",
    "            size, offset = int(realizations*0.15), int(realizations*0.70)\n",
    "        elif mode=='test':   \n",
    "            size, offset = int(realizations*0.15), int(realizations*0.85)\n",
    "        else:    raise Exception('Wrong name!')\n",
    "\n",
    "\n",
    "        # define size, input and output matrices\n",
    "        self.size   = size\n",
    "        self.input  = torch.zeros((size, 4), dtype=torch.float) # I think this is right.. \n",
    "        self.output = torch.zeros((size, 2),dtype=torch.float)\n",
    "\n",
    "        # fill matrices with the data\n",
    "        self.input[:] = observations[offset:offset+size]\n",
    "        self.output[:]  = actions[offset:offset+size]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input[idx], self.output[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(batch_size):\n",
    "    \n",
    "    train_Dataset = make_Dataset('train')\n",
    "    train_loader  = DataLoader(dataset=train_Dataset, batch_size=batch_size, \n",
    "                               shuffle=True)\n",
    "\n",
    "    valid_Dataset = make_Dataset('valid')\n",
    "    valid_loader  = DataLoader(dataset=valid_Dataset, batch_size=batch_size, \n",
    "                               shuffle=True)\n",
    "\n",
    "    test_Dataset  = make_Dataset('test')\n",
    "    test_loader   = DataLoader(dataset=test_Dataset,  batch_size=batch_size, \n",
    "                               shuffle=True)\n",
    "\n",
    "    return train_loader , valid_loader , test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader , valid_loader , test_loader  = create_datasets(batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input = Previous Observation \n",
    "\n",
    "# Output = Action to take"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based entirely on random training and seeing which actions perform best, nothing to do with Q learning (from what I can tell). If I wanted this to include some future discount of rewards, that information would need to be saved as a time series to predict future value versus current. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model, I'm going to use Pytorch (not Lightning) :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartpoleModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple 2 hidden layer network to learn based on observation, what move to make next. \n",
    "    \n",
    "    Output's a softmax so it is a probability :)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CartpoleModel, self).__init__()\n",
    "\n",
    "        self.fc1 = Linear(4, 128)\n",
    "        self.fc2 = Linear(128, 128)\n",
    "        self.fc3 = Linear(128, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.softmax(x,dim=1)\n",
    "        return output\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#initialize model parameters\n",
    "epochs       = 15\n",
    "learning_rate = 1e-3\n",
    "# weight_decay = 1e-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CartpoleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the network: 17410\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print('Total number of parameters in the network: %d'%total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device  cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"device \" , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best-model fname\n",
    "f_best_model = 'BestModel_Cartpole.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading best model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load best-model in case it exists\n",
    "if os.path.exists(f_best_model):  \n",
    "    print('loading best model...')\n",
    "    model.load_state_dict(torch.load(f_best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation error = 6.608e-01\n"
     ]
    }
   ],
   "source": [
    "# do validation with the best-model and compute loss\n",
    "model.eval() \n",
    "count, best_loss = 0, 0.0\n",
    "with torch.no_grad():\n",
    "    for observations, actions_true  in valid_loader:\n",
    "        actions_valid = model(observations)\n",
    "        error    = criterion(actions_valid, actions_true)\n",
    "        best_loss += error.cpu().numpy()\n",
    "        count += 1\n",
    "best_loss /= count\n",
    "print('validation error = %.3e'%best_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 6.5692e-01 6.5128e-01 3.6591e+01 (saving)\n",
      "001 6.4591e-01 6.4820e-01 3.6667e+01 (saving)\n",
      "002 6.4361e-01 6.4794e-01 3.6761e+01 (saving)\n",
      "003 6.4225e-01 6.4450e-01 3.6678e+01 (saving)\n",
      "004 6.4128e-01 6.4461e-01 3.6754e+01\n",
      "005 6.3927e-01 6.4886e-01 3.6878e+01\n",
      "006 6.3784e-01 6.4523e-01 3.6746e+01\n",
      "007 6.3803e-01 6.4645e-01 3.6857e+01\n",
      "008 6.3598e-01 6.4715e-01 3.6776e+01\n",
      "009 6.3609e-01 6.4798e-01 3.7249e+01\n",
      "010 6.3521e-01 6.5087e-01 3.6983e+01\n",
      "011 6.3615e-01 6.4736e-01 3.7094e+01\n",
      "012 6.3487e-01 6.4946e-01 3.6854e+01\n",
      "013 6.3491e-01 6.4854e-01 3.7031e+01\n",
      "014 6.3347e-01 6.5200e-01 3.7141e+01\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # TRAIN\n",
    "    model.train()\n",
    "    count, loss_train = 0, 0.0\n",
    "    for observations, actions_true in train_loader:\n",
    "        # Forward Pass\n",
    "        optimizer.zero_grad()\n",
    "        actions_pred = model(observations)\n",
    "        loss    = criterion(actions_pred, actions_true)\n",
    "        loss_train += loss.detach().numpy()\n",
    "        \n",
    "        # Backward Prop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    loss_train /= count\n",
    "    \n",
    "    \n",
    "    # VALID\n",
    "    model.eval() \n",
    "    count, loss_valid = 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for observations, actions_true  in valid_loader:\n",
    "            actions_pred = model(observations)\n",
    "            error    = criterion(actions_pred, actions_true)   \n",
    "            loss_valid += error.cpu().numpy()\n",
    "            count += 1\n",
    "    loss_valid /= count\n",
    "    \n",
    "    # TEST\n",
    "    model.eval() \n",
    "    count, loss_test = 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for observations, actions_true  in test_loader:\n",
    "          \n",
    "            actions_pred = model(observations)\n",
    "            error    = criterion(actions_pred, actions_true) \n",
    "            loss_test += error.cpu().numpy()\n",
    "            count += 1\n",
    "    \n",
    "    # Save Best Model \n",
    "    if loss_valid<best_loss:\n",
    "        best_loss = loss_valid\n",
    "        torch.save(model.state_dict(), f_best_model)\n",
    "        print('%03d %.4e %.4e %.4e (saving)'\\\n",
    "              %(epoch, loss_train, loss_valid, loss_test))    \n",
    "        \n",
    "    else:\n",
    "        print('%03d %.4e %.4e %.4e'%(epoch, loss_train, loss_valid, loss_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See how this best model does in the wild.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = CartpoleModel()\n",
    "model_best.load_state_dict(torch.load(f_best_model))\n",
    "#load best model in now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 200.0\n",
      "Worst Score: 200.0\n",
      "Average Score: 200.0\n",
      "choice 1:0.4985  choice 0:0.5015\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "choices = []\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "env.reset()\n",
    "for each_game in range(10):\n",
    "    score = 0\n",
    "    game_memory = []\n",
    "    prev_obs = []\n",
    "    env.reset()\n",
    "    for _ in range(goal_steps):\n",
    "        env.render()\n",
    "\n",
    "        if len(prev_obs)==0:\n",
    "            action = random.randrange(0,2)\n",
    "        else:\n",
    "            action = np.argmax(model_best.forward(torch.Tensor(prev_obs).view(1,4)).detach().numpy())\n",
    "\n",
    "        choices.append(action)\n",
    "                \n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        prev_obs = new_observation\n",
    "        game_memory.append([new_observation, action])\n",
    "        score+=reward\n",
    "        if done: break\n",
    "            \n",
    "    scores.append(score)\n",
    "    \n",
    "print('Best Score:',max(scores))\n",
    "print('Worst Score:',min(scores))\n",
    "\n",
    "print('Average Score:',sum(scores)/len(scores))\n",
    "print('choice 1:{}  choice 0:{}'.format(choices.count(1)/len(choices),choices.count(0)/len(choices)))\n",
    "print(score_requirement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's interesting is that it looks like this trains on data that never reaches 200, but can still get that far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
